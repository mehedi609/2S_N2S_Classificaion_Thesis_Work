{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-19T15:45:38.004829Z",
     "start_time": "2024-04-19T15:45:37.991383Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T13:36:31.084387Z",
     "start_time": "2024-04-17T13:36:31.077881Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a8858ad91ac492e2",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T15:45:40.705260Z",
     "start_time": "2024-04-19T15:45:39.951615Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from feature_extraction.CTFeatureExtraction import CTFeatureExtraction\n",
    "from feature_extraction.QSOFeatureExtraction import QSOFeatureExtraction\n",
    "from feature_extraction.GTPCFeatureExtraction import GTPCFeatureExtraction\n",
    "from feature_extraction.GDPCFeatureExtraction import GDPCFeatureExtraction\n",
    "from feature_extraction.CTDFeatureExtraction import CTDFeatureExtraction\n",
    "from feature_extraction.CKSAAPFeatureExtraction import CKSAAPFeatureExtraction\n",
    "from feature_extraction.AAIFeatureExtraction import AAIFeatureExtraction\n",
    "from feature_extraction.DDEFeatureExtraction import DDEFeatureExtraction\n",
    "from feature_extraction.DPCFeatureExtraction import DPCFeatureExtraction\n",
    "from feature_extraction.KAACFeatureExtraction import KAACFeatureExtraction\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_excel('../data/Final_2Sm_modified_with_sequences.xlsx')\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder to the folding_type column and transform it to numeric labels\n",
    "data['folding_type'] = label_encoder.fit_transform(data['folding_type'])\n",
    "\n",
    "# Extract labels for model training\n",
    "labels = data['folding_type'].values\n",
    "\n",
    "# Initialize the feature extraction objects\n",
    "kaac_extractor = KAACFeatureExtraction()\n",
    "dpc_extractor = DPCFeatureExtraction()\n",
    "dde_extractor = DDEFeatureExtraction()\n",
    "aai_extractor = AAIFeatureExtraction()\n",
    "cksaap_extractor = CKSAAPFeatureExtraction()\n",
    "ctd_extractor = CTDFeatureExtraction()\n",
    "gdpc_extractor = GDPCFeatureExtraction()\n",
    "gtpc_extractor = GTPCFeatureExtraction()\n",
    "qso_extractor = QSOFeatureExtraction()\n",
    "ct_extractor = CTFeatureExtraction()\n",
    "\n",
    "# Extract features using feature extracting methods\n",
    "kaac_features = np.array([kaac_extractor.calculate_kaac_features(seq) for seq in data['sequence']])\n",
    "dpc_features = np.array([dpc_extractor.calculate_dpc_features(seq) for seq in data['sequence']])\n",
    "dde_features = np.array([dde_extractor.calculate_dde_features(seq) for seq in data['sequence']])\n",
    "aai_features = np.array([aai_extractor.calculate_aai_features(seq) for seq in data['sequence']])\n",
    "cksaap_features = np.array([cksaap_extractor.calculate_cksaap_features(seq) for seq in data['sequence']])\n",
    "ctd_features = np.array([ctd_extractor.calculate_ctd_features(seq) for seq in data['sequence']])\n",
    "gdpc_features = np.array([gdpc_extractor.calculate_gdpc_features(seq) for seq in data['sequence']])\n",
    "gtpc_features = np.array([gtpc_extractor.calculate_gtpc_features(seq) for seq in data['sequence']])\n",
    "qso_features = np.array([qso_extractor.calculate_qso_features(seq) for seq in data['sequence']])\n",
    "ct_features = np.array([ct_extractor.calculate_ct_features(seq) for seq in data['sequence']])\n",
    "\n",
    "# Combine the extracted features\n",
    "combined_features = np.concatenate((kaac_features, dpc_features, dde_features), axis=1)"
   ],
   "id": "2ce95aa12f0d905",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T11:30:57.095301Z",
     "start_time": "2024-04-19T11:30:57.081299Z"
    }
   },
   "cell_type": "code",
   "source": "combined_features.shape",
   "id": "a290ba3447814685",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141, 821)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "644fd884e5d98887"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T21:41:07.803576Z",
     "start_time": "2024-04-19T20:11:04.145756Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(combined_features)\n",
    "\n",
    "# Create a pipeline with scaling and ANN classifier\n",
    "pipeline = Pipeline([\n",
    "    ('ann', MLPClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "param_grid = {\n",
    "    'ann__hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 100)],\n",
    "    'ann__activation': ['relu', 'logistic', 'tanh'],\n",
    "    'ann__solver': ['adam', 'sgd'],\n",
    "    'ann__alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'ann__learning_rate_init': [0.001, 0.01, 0.1],\n",
    "    'ann__learning_rate': ['constant', 'adaptive', 'invscaling'],\n",
    "    'ann__max_iter': [500, 1000, 2000],\n",
    "    'ann__tol': [1e-4, 1e-5, 1e-6]\n",
    "}\n",
    "\n",
    "# Create a custom scorer that returns the score and prints progress\n",
    "def custom_scorer(estimator, X, y):\n",
    "    score = estimator.score(X, y)\n",
    "    print(f\"Score: {score:.3f}\")\n",
    "    return score\n",
    "\n",
    "# Perform grid search with 3-fold cross-validation and progress bar\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    scoring=custom_scorer,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Wrap the grid search with tqdm_notebook\n",
    "with tqdm_notebook(total=len(grid_search.param_grid), desc=\"Grid Search\") as progress_bar:\n",
    "    for _ in grid_search.fit(scaled_features, labels):\n",
    "        progress_bar.update(1)\n",
    "\n",
    "# Get the best classifier\n",
    "best_ann_clf = grid_search.best_estimator_"
   ],
   "id": "c015507fb04d1feb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehedi\\AppData\\Local\\Temp\\ipykernel_36752\\3516035644.py:45: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  with tqdm_notebook(total=len(grid_search.param_grid), desc=\"Grid Search\") as progress_bar:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Grid Search:   0%|          | 0/8 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ed5f813928fc45d39ccabbdf85254fa7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'GridSearchCV' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 46\u001B[0m\n\u001B[0;32m     44\u001B[0m \u001B[38;5;66;03m# Wrap the grid search with tqdm_notebook\u001B[39;00m\n\u001B[0;32m     45\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tqdm_notebook(total\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(grid_search\u001B[38;5;241m.\u001B[39mparam_grid), desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGrid Search\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m progress_bar:\n\u001B[1;32m---> 46\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m grid_search\u001B[38;5;241m.\u001B[39mfit(scaled_features, labels):\n\u001B[0;32m     47\u001B[0m         progress_bar\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     49\u001B[0m \u001B[38;5;66;03m# Get the best classifier\u001B[39;00m\n",
      "\u001B[1;31mTypeError\u001B[0m: 'GridSearchCV' object is not iterable"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4069aaeec59b1efa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-20T03:41:56.616532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from feature_extraction.ClassificationMatrix import ClassificationMatrix\n",
    "\n",
    "# Perform leave-one-out cross-validation with the best classifier\n",
    "loo = LeaveOneOut()\n",
    "y_true, y_pred = [], []\n",
    "for train_index, test_index in loo.split(combined_features):\n",
    "    X_train, X_test = combined_features[train_index], combined_features[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    best_ann_clf.fit(X_train, y_train)\n",
    "    y_pred.append(best_ann_clf.predict(X_test)[0])\n",
    "    y_true.append(y_test[0])\n",
    "\n",
    "# Calculate and display the confusion matrix\n",
    "cm = ClassificationMatrix(y_true, y_pred, 'ANN Classifier')\n",
    "cm.evaluate()"
   ],
   "id": "e905d3773c981be0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "e1bd60e9709e5061"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T15:27:06.652022Z",
     "start_time": "2024-04-19T15:27:04.143070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(combined_features)\n",
    "\n",
    "# Define the ANN model\n",
    "def create_model(units=128, dropout_rate=0.2, optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units, activation='relu', input_shape=(scaled_features.shape[1],)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units//2, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(len(np.unique(labels)), activation='softmax'))\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create the ANN classifier\n",
    "ann_classifier = KerasClassifier(build_fn=create_model, epochs=100, batch_size=32, verbose=0)"
   ],
   "id": "c9a65d39f48f35d4",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras.wrappers'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Sequential\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlayers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Dense, Dropout\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mwrappers\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mscikit_learn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m KerasClassifier\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# Scale the features\u001B[39;00m\n\u001B[0;32m      6\u001B[0m scaler \u001B[38;5;241m=\u001B[39m StandardScaler()\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'tensorflow.keras.wrappers'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T16:08:24.810993Z",
     "start_time": "2024-04-19T16:08:19.511090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, classification_report, confusion_matrix\n",
    "\n",
    "# Scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# scaled_features = scaler.fit_transform(combined_features)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_features, labels, test_size=0.2, random_state=42)\n",
    "# Scale the features\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the hyperparameter search space\n",
    "def build_model(hp):\n",
    "    inputs = layers.Input(shape=(scaled_features.shape[1],))\n",
    "    x = layers.Dense(units=hp.Int('units_input', min_value=32, max_value=512, step=32), activation='relu')(inputs)\n",
    "\n",
    "    for i in range(hp.Int('num_layers', 1, 5)):\n",
    "        x = layers.Dense(units=hp.Int(f'units_{i}', min_value=32, max_value=512, step=32), activation='relu')(x)\n",
    "\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create a tuner\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=3,\n",
    "    directory='tuner_results',\n",
    "    project_name='folding_type_classification'\n",
    ")\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "tuner.search(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Get the best hyperparameters and build the best model\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Train the best model\n",
    "history = best_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)\n",
    "\n"
   ],
   "id": "e23b9323e13ee1ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from tuner_results\\folding_type_classification\\tuner0.json\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 56ms/step - accuracy: 0.5070 - loss: 0.8496 - val_accuracy: 0.5217 - val_loss: 1.4892\n",
      "Epoch 2/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.7634 - loss: 0.4119 - val_accuracy: 0.6087 - val_loss: 0.8897\n",
      "Epoch 3/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9731 - loss: 0.0905 - val_accuracy: 0.5217 - val_loss: 0.8900\n",
      "Epoch 4/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 0.0348 - val_accuracy: 0.5652 - val_loss: 1.0074\n",
      "Epoch 5/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 0.0113 - val_accuracy: 0.5652 - val_loss: 1.1716\n",
      "Epoch 6/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.5652 - val_loss: 1.3343\n",
      "Epoch 7/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.5217 - val_loss: 1.4726\n",
      "Epoch 8/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.5217 - val_loss: 1.5816\n",
      "Epoch 9/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 1.0000 - loss: 9.7969e-04 - val_accuracy: 0.5652 - val_loss: 1.6649\n",
      "Epoch 10/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.5652 - val_loss: 1.7241\n",
      "Epoch 11/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 7.3128e-04 - val_accuracy: 0.5652 - val_loss: 1.7667\n",
      "Epoch 12/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 6.3968e-04 - val_accuracy: 0.5652 - val_loss: 1.7951\n",
      "Epoch 13/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 1.0000 - loss: 5.0198e-04 - val_accuracy: 0.5652 - val_loss: 1.8137\n",
      "Epoch 14/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 1.0000 - loss: 4.1842e-04 - val_accuracy: 0.5652 - val_loss: 1.8252\n",
      "Epoch 15/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 3.1214e-04 - val_accuracy: 0.5652 - val_loss: 1.8319\n",
      "Epoch 16/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 3.4318e-04 - val_accuracy: 0.5652 - val_loss: 1.8345\n",
      "Epoch 17/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 2.9326e-04 - val_accuracy: 0.5652 - val_loss: 1.8348\n",
      "Epoch 18/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 2.6867e-04 - val_accuracy: 0.5652 - val_loss: 1.8336\n",
      "Epoch 19/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 2.5062e-04 - val_accuracy: 0.5652 - val_loss: 1.8317\n",
      "Epoch 20/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 2.2524e-04 - val_accuracy: 0.5652 - val_loss: 1.8289\n",
      "Epoch 21/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 2.2957e-04 - val_accuracy: 0.5652 - val_loss: 1.8259\n",
      "Epoch 22/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 2.2029e-04 - val_accuracy: 0.5652 - val_loss: 1.8229\n",
      "Epoch 23/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 1.0000 - loss: 2.0990e-04 - val_accuracy: 0.5652 - val_loss: 1.8200\n",
      "Epoch 24/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 1.0000 - loss: 1.8837e-04 - val_accuracy: 0.5652 - val_loss: 1.8174\n",
      "Epoch 25/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 1.6269e-04 - val_accuracy: 0.5652 - val_loss: 1.8151\n",
      "Epoch 26/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 1.6988e-04 - val_accuracy: 0.5652 - val_loss: 1.8129\n",
      "Epoch 27/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 1.5995e-04 - val_accuracy: 0.5652 - val_loss: 1.8107\n",
      "Epoch 28/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 1.5134e-04 - val_accuracy: 0.5652 - val_loss: 1.8089\n",
      "Epoch 29/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 1.0000 - loss: 1.5460e-04 - val_accuracy: 0.5652 - val_loss: 1.8074\n",
      "Epoch 30/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 1.0000 - loss: 1.4000e-04 - val_accuracy: 0.5652 - val_loss: 1.8060\n",
      "Epoch 31/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 1.0000 - loss: 1.4071e-04 - val_accuracy: 0.5652 - val_loss: 1.8048\n",
      "Epoch 32/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 1.2222e-04 - val_accuracy: 0.5652 - val_loss: 1.8040\n",
      "Epoch 33/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 1.3753e-04 - val_accuracy: 0.5652 - val_loss: 1.8030\n",
      "Epoch 34/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 1.1759e-04 - val_accuracy: 0.5652 - val_loss: 1.8023\n",
      "Epoch 35/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 1.2756e-04 - val_accuracy: 0.5652 - val_loss: 1.8017\n",
      "Epoch 36/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 1.0000 - loss: 1.1440e-04 - val_accuracy: 0.5652 - val_loss: 1.8012\n",
      "Epoch 37/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 1.0756e-04 - val_accuracy: 0.5652 - val_loss: 1.8009\n",
      "Epoch 38/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 1.1127e-04 - val_accuracy: 0.5652 - val_loss: 1.8008\n",
      "Epoch 39/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 1.1225e-04 - val_accuracy: 0.5652 - val_loss: 1.8009\n",
      "Epoch 40/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 1.1345e-04 - val_accuracy: 0.5652 - val_loss: 1.8009\n",
      "Epoch 41/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 1.1052e-04 - val_accuracy: 0.5652 - val_loss: 1.8010\n",
      "Epoch 42/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 9.7277e-05 - val_accuracy: 0.5652 - val_loss: 1.8012\n",
      "Epoch 43/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 1.0522e-04 - val_accuracy: 0.5652 - val_loss: 1.8016\n",
      "Epoch 44/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 9.6600e-05 - val_accuracy: 0.5652 - val_loss: 1.8021\n",
      "Epoch 45/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 8.6765e-05 - val_accuracy: 0.5652 - val_loss: 1.8026\n",
      "Epoch 46/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 9.6432e-05 - val_accuracy: 0.5652 - val_loss: 1.8030\n",
      "Epoch 47/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 8.7801e-05 - val_accuracy: 0.5652 - val_loss: 1.8037\n",
      "Epoch 48/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 9.0117e-05 - val_accuracy: 0.5652 - val_loss: 1.8044\n",
      "Epoch 49/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 1.0000 - loss: 9.0746e-05 - val_accuracy: 0.5652 - val_loss: 1.8051\n",
      "Epoch 50/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 8.9691e-05 - val_accuracy: 0.5652 - val_loss: 1.8057\n",
      "Epoch 51/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 1.0000 - loss: 8.8053e-05 - val_accuracy: 0.5652 - val_loss: 1.8064\n",
      "Epoch 52/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 7.8252e-05 - val_accuracy: 0.5652 - val_loss: 1.8074\n",
      "Epoch 53/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 8.5124e-05 - val_accuracy: 0.5652 - val_loss: 1.8083\n",
      "Epoch 54/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 1.0000 - loss: 7.6802e-05 - val_accuracy: 0.5652 - val_loss: 1.8093\n",
      "Epoch 55/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 7.9537e-05 - val_accuracy: 0.5652 - val_loss: 1.8104\n",
      "Epoch 56/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 7.8463e-05 - val_accuracy: 0.5652 - val_loss: 1.8115\n",
      "Epoch 57/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 1.0000 - loss: 7.5442e-05 - val_accuracy: 0.5652 - val_loss: 1.8126\n",
      "Epoch 58/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 7.2906e-05 - val_accuracy: 0.5652 - val_loss: 1.8138\n",
      "Epoch 59/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 7.9265e-05 - val_accuracy: 0.5652 - val_loss: 1.8148\n",
      "Epoch 60/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 7.0154e-05 - val_accuracy: 0.5652 - val_loss: 1.8161\n",
      "Epoch 61/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 7.1689e-05 - val_accuracy: 0.5652 - val_loss: 1.8172\n",
      "Epoch 62/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 7.5978e-05 - val_accuracy: 0.5652 - val_loss: 1.8185\n",
      "Epoch 63/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 6.9676e-05 - val_accuracy: 0.5652 - val_loss: 1.8198\n",
      "Epoch 64/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 6.4635e-05 - val_accuracy: 0.5652 - val_loss: 1.8212\n",
      "Epoch 65/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 6.8804e-05 - val_accuracy: 0.5652 - val_loss: 1.8225\n",
      "Epoch 66/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 6.9410e-05 - val_accuracy: 0.5652 - val_loss: 1.8239\n",
      "Epoch 67/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 6.7442e-05 - val_accuracy: 0.5652 - val_loss: 1.8253\n",
      "Epoch 68/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 5.9705e-05 - val_accuracy: 0.5652 - val_loss: 1.8268\n",
      "Epoch 69/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 5.8476e-05 - val_accuracy: 0.5652 - val_loss: 1.8284\n",
      "Epoch 70/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 6.0769e-05 - val_accuracy: 0.5652 - val_loss: 1.8298\n",
      "Epoch 71/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 6.2378e-05 - val_accuracy: 0.5652 - val_loss: 1.8313\n",
      "Epoch 72/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 1.0000 - loss: 5.9430e-05 - val_accuracy: 0.5652 - val_loss: 1.8328\n",
      "Epoch 73/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 5.5958e-05 - val_accuracy: 0.5652 - val_loss: 1.8343\n",
      "Epoch 74/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 5.5091e-05 - val_accuracy: 0.5652 - val_loss: 1.8358\n",
      "Epoch 75/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 5.6569e-05 - val_accuracy: 0.5652 - val_loss: 1.8372\n",
      "Epoch 76/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 5.8551e-05 - val_accuracy: 0.5652 - val_loss: 1.8386\n",
      "Epoch 77/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 5.5738e-05 - val_accuracy: 0.5652 - val_loss: 1.8402\n",
      "Epoch 78/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 5.5834e-05 - val_accuracy: 0.5652 - val_loss: 1.8417\n",
      "Epoch 79/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 5.4723e-05 - val_accuracy: 0.5652 - val_loss: 1.8433\n",
      "Epoch 80/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 5.4939e-05 - val_accuracy: 0.5652 - val_loss: 1.8448\n",
      "Epoch 81/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 4.9574e-05 - val_accuracy: 0.5652 - val_loss: 1.8464\n",
      "Epoch 82/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 4.9434e-05 - val_accuracy: 0.5652 - val_loss: 1.8481\n",
      "Epoch 83/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 4.4595e-05 - val_accuracy: 0.5652 - val_loss: 1.8497\n",
      "Epoch 84/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 4.9738e-05 - val_accuracy: 0.5652 - val_loss: 1.8514\n",
      "Epoch 85/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 5.1880e-05 - val_accuracy: 0.5652 - val_loss: 1.8530\n",
      "Epoch 86/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 4.5736e-05 - val_accuracy: 0.5652 - val_loss: 1.8547\n",
      "Epoch 87/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 4.9204e-05 - val_accuracy: 0.5652 - val_loss: 1.8562\n",
      "Epoch 88/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 4.6315e-05 - val_accuracy: 0.5652 - val_loss: 1.8579\n",
      "Epoch 89/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 4.1916e-05 - val_accuracy: 0.5652 - val_loss: 1.8595\n",
      "Epoch 90/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 4.1181e-05 - val_accuracy: 0.5652 - val_loss: 1.8611\n",
      "Epoch 91/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 4.6057e-05 - val_accuracy: 0.5652 - val_loss: 1.8626\n",
      "Epoch 92/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 4.3286e-05 - val_accuracy: 0.5652 - val_loss: 1.8642\n",
      "Epoch 93/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 4.2447e-05 - val_accuracy: 0.5652 - val_loss: 1.8658\n",
      "Epoch 94/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 3.9334e-05 - val_accuracy: 0.5652 - val_loss: 1.8674\n",
      "Epoch 95/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 4.4154e-05 - val_accuracy: 0.5652 - val_loss: 1.8690\n",
      "Epoch 96/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 4.1541e-05 - val_accuracy: 0.5652 - val_loss: 1.8706\n",
      "Epoch 97/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 3.7363e-05 - val_accuracy: 0.5652 - val_loss: 1.8722\n",
      "Epoch 98/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 4.0277e-05 - val_accuracy: 0.5652 - val_loss: 1.8739\n",
      "Epoch 99/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 3.8595e-05 - val_accuracy: 0.5652 - val_loss: 1.8754\n",
      "Epoch 100/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 4.1431e-05 - val_accuracy: 0.5652 - val_loss: 1.8770\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T16:07:49.895238Z",
     "start_time": "2024-04-19T16:07:49.838354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {test_acc:.4f}')"
   ],
   "id": "bf3a1082b0298640",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.7586 - loss: 1.0769\n",
      "Test accuracy: 0.7586\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T16:07:59.172882Z",
     "start_time": "2024-04-19T16:07:59.091892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate the model on the test set\n",
    "y_pred_prob = best_model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Matthews Correlation Coefficient:\", mcc)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Calculate and display the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ],
   "id": "aa109e1c79ff490",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step\n",
      "Accuracy: 0.7586206896551724\n",
      "Matthews Correlation Coefficient: 0.545205169866058\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.93      0.80        15\n",
      "           1       0.89      0.57      0.70        14\n",
      "\n",
      "    accuracy                           0.76        29\n",
      "   macro avg       0.79      0.75      0.75        29\n",
      "weighted avg       0.79      0.76      0.75        29\n",
      "\n",
      "Confusion Matrix:\n",
      "[[14  1]\n",
      " [ 6  8]]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T15:57:13.484833Z",
     "start_time": "2024-04-19T15:57:12.608046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner import HyperModel, RandomSearch\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define a class to create the ANN model with hyperparameter tuning\n",
    "class ANNHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = keras.Sequential()\n",
    "        model.add(layers.InputLayer(input_shape=self.input_shape))\n",
    "\n",
    "        # Tune the number of layers, units, and activation\n",
    "        for i in range(hp.Int('num_layers', 1, 3)):\n",
    "            model.add(layers.Dense(units=hp.Int('units_' + str(i), min_value=32, max_value=512, step=32),\n",
    "                                   activation=hp.Choice('activation_' + str(i), ['relu', 'tanh', 'sigmoid'])))\n",
    "            model.add(layers.Dropout(rate=hp.Float('dropout_' + str(i), min_value=0.0, max_value=0.5, step=0.1)))\n",
    "\n",
    "        model.add(layers.Dense(self.num_classes, activation='softmax'))\n",
    "        model.compile(optimizer=keras.optimizers.Adam(hp.Float('learning_rate', 1e-4, 1e-2, sampling='log')),\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "# Instantiate and configure the Keras Tuner\n",
    "hypermodel = ANNHyperModel(input_shape=(X_train.shape[1],), num_classes=len(np.unique(labels)))\n",
    "tuner = RandomSearch(\n",
    "    hypermodel,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=2,\n",
    "    directory='keras_tuner_dir',\n",
    "    project_name='keras_tuner_demo'\n",
    ")\n",
    "\n",
    "# Execute the hyperparameter search\n",
    "tuner.search(X_train, y_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "# Retrieve the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Evaluate the best model on the test data\n",
    "loss, accuracy = best_model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {accuracy}, Test loss: {loss}')"
   ],
   "id": "4ac78b693382de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from keras_tuner_dir\\keras_tuner_demo\\tuner0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\keras\\src\\layers\\core\\input_layer.py:25: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehedi\\anaconda3\\envs\\tnsr_evn\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:418: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 14 variables. \n",
      "  trackable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 172ms/step - accuracy: 0.5862 - loss: 0.7209\n",
      "Test accuracy: 0.5862069129943848, Test loss: 0.7209303379058838\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4a5cbd913603e67c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
