{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-16T16:23:58.042830Z",
     "start_time": "2024-04-16T16:23:58.027330Z"
    }
   },
   "source": [
    "from collections import Counter\n",
    "\n",
    "class KAACFeatureExtraction:\n",
    "    def __init__(self):\n",
    "        self.amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "\n",
    "    def calculate_kaac_features(self, sequence):\n",
    "        \"\"\"\n",
    "        Calculate the KAAC features for a given protein sequence.\n",
    "\n",
    "        :param sequence: The protein sequence as a string.\n",
    "        :return: A list of KAAC feature values.\n",
    "        \"\"\"\n",
    "        # Calculate the amino acid composition (AAC)\n",
    "        aac_features = self.calculate_aac_features(sequence)\n",
    "\n",
    "        # Calculate the sequence length (K)\n",
    "        sequence_length = len(sequence)\n",
    "\n",
    "        # Combine AAC features with sequence length\n",
    "        kaac_features = aac_features + [sequence_length]\n",
    "\n",
    "        return kaac_features\n",
    "\n",
    "    def calculate_aac_features(self, sequence):\n",
    "        \"\"\"\n",
    "        Calculate the amino acid composition (AAC) features.\n",
    "\n",
    "        :param sequence: The protein sequence as a string.\n",
    "        :return: A list of AAC feature values.\n",
    "        \"\"\"\n",
    "        # Count the occurrences of each amino acid in the sequence\n",
    "        amino_acid_counts = Counter(sequence)\n",
    "\n",
    "        # Calculate the total number of amino acids in the sequence\n",
    "        total_amino_acids = sum(amino_acid_counts.values())\n",
    "\n",
    "        # Calculate the normalized frequency of each amino acid\n",
    "        aac_features = [amino_acid_counts.get(aa, 0) / total_amino_acids for aa in self.amino_acids]\n",
    "\n",
    "        return aac_features"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, matthews_corrcoef\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_excel('../data/Final_2Sm_modified_with_sequences.xlsx')\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder to the folding_type column and transform it to numeric labels\n",
    "data['folding_type'] = label_encoder.fit_transform(data['folding_type'])\n",
    "\n",
    "# Now, when you extract labels for model training:\n",
    "labels = data['folding_type'].values\n",
    "\n",
    "# Initialize the FeatureExtraction class\n",
    "feature_extraction = KAACFeatureExtraction()\n",
    "\n",
    "# Feature extraction using AAC with length\n",
    "features = np.array([feature_extraction.calculate_kaac_features(seq) for seq in data['sequence']])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T16:24:01.438740Z",
     "start_time": "2024-04-16T16:24:01.239981Z"
    }
   },
   "id": "a062d17d57f88a46",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SUPPORT VECTOR MACHINE (SVM) Implementation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "503d3efb254b7dac"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# SVM with Leave-One-Out Cross-Validation (LOOCV)\n",
    "loo = LeaveOneOut()\n",
    "y_true, y_pred = [], []\n",
    "for train_index, test_index in loo.split(features):\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    clf = SVC(kernel='linear')\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred.append(clf.predict(X_test)[0])\n",
    "    y_true.append(y_test[0])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2bae469594af895",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: $KAAC\n",
      "[[81  8]\n",
      " [22 30]]\n",
      "\n",
      "Accuracy (ACC): 0.79\n",
      "Matthews Correlation Coefficient (MCC): 0.53\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.91      0.84        89\n",
      "           1       0.79      0.58      0.67        52\n",
      "\n",
      "    accuracy                           0.79       141\n",
      "   macro avg       0.79      0.74      0.76       141\n",
      "weighted avg       0.79      0.79      0.78       141\n"
     ]
    }
   ],
   "source": [
    "# Calculate and display the confusion matrix\n",
    "from ClassificationMatrix import ClassificationMatrix\n",
    "\n",
    "cm = ClassificationMatrix(y_true, y_pred, 'KAAC')\n",
    "cm.evaluate()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T09:48:53.221440Z",
     "start_time": "2024-04-16T09:48:53.201938Z"
    }
   },
   "id": "190ad0b40905d6a3",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RANDOM FOREST (RF) Implementation with Hyperparameter Tuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9d9c6a2dea675fe"
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define the parameter grid\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Grid search with cross validation setup\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=rf_param_grid, cv=3, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to find the best parameters\n",
    "grid_search.fit(features, labels)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best parameters: \", best_params)\n",
    "print(\"Best score: \", best_score)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T15:55:11.711429Z",
     "start_time": "2024-04-16T15:53:56.827918Z"
    }
   },
   "id": "2e100a0a82139363",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Best score:  0.7588652482269503\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Using the best parameters with LOOCV\n",
    "best_rf = RandomForestClassifier(**best_params, random_state=42)\n",
    "loo = LeaveOneOut()\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "for train_index, test_index in loo.split(features):\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    best_rf.fit(X_train, y_train)\n",
    "    y_pred.append(best_rf.predict(X_test)[0])\n",
    "    y_true.append(y_test[0])"
   ],
   "id": "f31335c8e336d77e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: $KAAC\n",
      "[[84  5]\n",
      " [23 29]]\n",
      "\n",
      "Accuracy (ACC): 0.80\n",
      "Matthews Correlation Coefficient (MCC): 0.57\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.94      0.86        89\n",
      "           1       0.85      0.56      0.67        52\n",
      "\n",
      "    accuracy                           0.80       141\n",
      "   macro avg       0.82      0.75      0.77       141\n",
      "weighted avg       0.81      0.80      0.79       141\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "# Calculate and display the confusion matrix\n",
    "from ClassificationMatrix import ClassificationMatrix\n",
    "\n",
    "cm = ClassificationMatrix(y_true, y_pred, 'KAAC')\n",
    "cm.evaluate()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T13:51:40.900135Z",
     "start_time": "2024-04-16T13:51:40.882614Z"
    }
   },
   "id": "aac476335fb30a21",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e5d1e6575e63ff45",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ebbf60729c2e661e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-16T16:24:11.399123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GridSearchCV, LeaveOneOut, ShuffleSplit\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Define the parameter grid for Kernel SVM\n",
    "svm_param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Initialize the Kernel SVM classifier\n",
    "svm = SVC(random_state=42)\n",
    "\n",
    "# Grid search with cross-validation setup\n",
    "cv = ShuffleSplit(n_splits=3, test_size=0.2, random_state=42)\n",
    "grid_search = GridSearchCV(estimator=svm, param_grid=svm_param_grid, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to find the best parameters\n",
    "grid_search.fit(features, labels)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best parameters: \", best_params)\n",
    "print(\"Best score: \", best_score)\n",
    "\n"
   ],
   "id": "a56aee3f4810dd51",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Using the best parameters with LOOCV\n",
    "best_svm = SVC(**best_params, random_state=42)\n",
    "loo = LeaveOneOut()\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "for train_index, test_index in loo.split(features):\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    best_svm.fit(X_train, y_train)\n",
    "    y_pred.append(best_svm.predict(X_test)[0])\n",
    "    y_true.append(y_test[0])"
   ],
   "id": "b5bce7161af011c3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Evaluate the model\n",
    "# Calculate and display the confusion matrix\n",
    "from ClassificationMatrix import ClassificationMatrix\n",
    "\n",
    "cm = ClassificationMatrix(y_true, y_pred, 'KAAC')\n",
    "cm.evaluate()"
   ],
   "id": "231351ab456fca6d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "3940347c2c9415ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T16:07:10.599403Z",
     "start_time": "2024-04-16T16:07:08.716304Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.utils import to_categorical"
   ],
   "id": "efeea2cc5938cbec",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehedi\\anaconda3\\envs\\Thesis_Work\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:513: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  np.object,\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'object'.\n`np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. \nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_selection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GridSearchCV\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Sequential\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlayers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mwrappers\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mscikit_learn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m KerasClassifier\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Thesis_Work\\lib\\site-packages\\tensorflow\\__init__.py:41\u001B[0m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msix\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01m_six\u001B[39;00m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msys\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01m_sys\u001B[39;00m\n\u001B[1;32m---> 41\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtools\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m module_util \u001B[38;5;28;01mas\u001B[39;00m _module_util\n\u001B[0;32m     42\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlazy_loader\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LazyLoader \u001B[38;5;28;01mas\u001B[39;00m _LazyLoader\n\u001B[0;32m     44\u001B[0m \u001B[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Thesis_Work\\lib\\site-packages\\tensorflow\\python\\__init__.py:45\u001B[0m\n\u001B[0;32m     40\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01meager\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m context\n\u001B[0;32m     42\u001B[0m \u001B[38;5;66;03m# pylint: enable=wildcard-import\u001B[39;00m\n\u001B[0;32m     43\u001B[0m \n\u001B[0;32m     44\u001B[0m \u001B[38;5;66;03m# Bring in subpackages.\u001B[39;00m\n\u001B[1;32m---> 45\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m data\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m distribute\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m keras\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Thesis_Work\\lib\\site-packages\\tensorflow\\python\\data\\__init__.py:25\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m__future__\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m print_function\n\u001B[0;32m     24\u001B[0m \u001B[38;5;66;03m# pylint: disable=unused-import\u001B[39;00m\n\u001B[1;32m---> 25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m experimental\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdataset_ops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Dataset\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdataset_ops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m INFINITE \u001B[38;5;28;01mas\u001B[39;00m INFINITE_CARDINALITY\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Thesis_Work\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py:96\u001B[0m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m__future__\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m print_function\n\u001B[0;32m     95\u001B[0m \u001B[38;5;66;03m# pylint: disable=unused-import\u001B[39;00m\n\u001B[1;32m---> 96\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexperimental\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m service\n\u001B[0;32m     97\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexperimental\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbatching\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dense_to_ragged_batch\n\u001B[0;32m     98\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexperimental\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbatching\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dense_to_sparse_batch\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Thesis_Work\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\service\\__init__.py:21\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m__future__\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m division\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m__future__\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m print_function\n\u001B[1;32m---> 21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexperimental\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata_service_ops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m distribute\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexperimental\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mservice\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mserver_lib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DispatchServer\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexperimental\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mservice\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mserver_lib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m WorkerServer\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Thesis_Work\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\data_service_ops.py:25\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msix\u001B[39;00m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tf2\n\u001B[1;32m---> 25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexperimental\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m compression_ops\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexperimental\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdistribute_options\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AutoShardPolicy\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexperimental\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdistribute_options\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ExternalStatePolicy\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Thesis_Work\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\compression_ops.py:20\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m__future__\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m division\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m__future__\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m print_function\n\u001B[1;32m---> 20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m structure\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m gen_experimental_dataset_ops \u001B[38;5;28;01mas\u001B[39;00m ged_ops\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompress\u001B[39m(element):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Thesis_Work\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:26\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msix\u001B[39;00m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mwrapt\u001B[39;00m\n\u001B[1;32m---> 26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m nest\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m composite_tensor\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ops\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Thesis_Work\\lib\\site-packages\\tensorflow\\python\\data\\util\\nest.py:41\u001B[0m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msix\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01m_six\u001B[39;00m\n\u001B[0;32m     40\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _pywrap_utils\n\u001B[1;32m---> 41\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m sparse_tensor \u001B[38;5;28;01mas\u001B[39;00m _sparse_tensor\n\u001B[0;32m     42\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m collections_abc \u001B[38;5;28;01mas\u001B[39;00m _collections_abc\n\u001B[0;32m     45\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_sorted\u001B[39m(dict_):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Thesis_Work\\lib\\site-packages\\tensorflow\\python\\framework\\sparse_tensor.py:29\u001B[0m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tf2\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m composite_tensor\n\u001B[1;32m---> 29\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m constant_op\n\u001B[0;32m     30\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dtypes\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ops\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Thesis_Work\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:29\u001B[0m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m types_pb2\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01meager\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m context\n\u001B[1;32m---> 29\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01meager\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m execute\n\u001B[0;32m     30\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dtypes\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m op_callbacks\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Thesis_Work\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:27\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pywrap_tfe\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01meager\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m core\n\u001B[1;32m---> 27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dtypes\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ops\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tensor_shape\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Thesis_Work\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:513\u001B[0m\n\u001B[0;32m    482\u001B[0m     _NP_TO_TF[pdt] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(\n\u001B[0;32m    483\u001B[0m         _NP_TO_TF[dt] \u001B[38;5;28;01mfor\u001B[39;00m dt \u001B[38;5;129;01min\u001B[39;00m _NP_TO_TF \u001B[38;5;28;01mif\u001B[39;00m dt \u001B[38;5;241m==\u001B[39m pdt()\u001B[38;5;241m.\u001B[39mdtype)\n\u001B[0;32m    486\u001B[0m TF_VALUE_DTYPES \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m(_NP_TO_TF\u001B[38;5;241m.\u001B[39mvalues())\n\u001B[0;32m    489\u001B[0m _TF_TO_NP \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    490\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_HALF:\n\u001B[0;32m    491\u001B[0m         np\u001B[38;5;241m.\u001B[39mfloat16,\n\u001B[0;32m    492\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_FLOAT:\n\u001B[0;32m    493\u001B[0m         np\u001B[38;5;241m.\u001B[39mfloat32,\n\u001B[0;32m    494\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_DOUBLE:\n\u001B[0;32m    495\u001B[0m         np\u001B[38;5;241m.\u001B[39mfloat64,\n\u001B[0;32m    496\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_INT32:\n\u001B[0;32m    497\u001B[0m         np\u001B[38;5;241m.\u001B[39mint32,\n\u001B[0;32m    498\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_UINT8:\n\u001B[0;32m    499\u001B[0m         np\u001B[38;5;241m.\u001B[39muint8,\n\u001B[0;32m    500\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_UINT16:\n\u001B[0;32m    501\u001B[0m         np\u001B[38;5;241m.\u001B[39muint16,\n\u001B[0;32m    502\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_UINT32:\n\u001B[0;32m    503\u001B[0m         np\u001B[38;5;241m.\u001B[39muint32,\n\u001B[0;32m    504\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_UINT64:\n\u001B[0;32m    505\u001B[0m         np\u001B[38;5;241m.\u001B[39muint64,\n\u001B[0;32m    506\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_INT16:\n\u001B[0;32m    507\u001B[0m         np\u001B[38;5;241m.\u001B[39mint16,\n\u001B[0;32m    508\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_INT8:\n\u001B[0;32m    509\u001B[0m         np\u001B[38;5;241m.\u001B[39mint8,\n\u001B[0;32m    510\u001B[0m     \u001B[38;5;66;03m# NOTE(touts): For strings we use np.object as it supports variable length\u001B[39;00m\n\u001B[0;32m    511\u001B[0m     \u001B[38;5;66;03m# strings.\u001B[39;00m\n\u001B[0;32m    512\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_STRING:\n\u001B[1;32m--> 513\u001B[0m         \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mobject\u001B[49m,\n\u001B[0;32m    514\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_COMPLEX64:\n\u001B[0;32m    515\u001B[0m         np\u001B[38;5;241m.\u001B[39mcomplex64,\n\u001B[0;32m    516\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_COMPLEX128:\n\u001B[0;32m    517\u001B[0m         np\u001B[38;5;241m.\u001B[39mcomplex128,\n\u001B[0;32m    518\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_INT64:\n\u001B[0;32m    519\u001B[0m         np\u001B[38;5;241m.\u001B[39mint64,\n\u001B[0;32m    520\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_BOOL:\n\u001B[0;32m    521\u001B[0m         np\u001B[38;5;241m.\u001B[39mbool,\n\u001B[0;32m    522\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_QINT8:\n\u001B[0;32m    523\u001B[0m         _np_qint8,\n\u001B[0;32m    524\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_QUINT8:\n\u001B[0;32m    525\u001B[0m         _np_quint8,\n\u001B[0;32m    526\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_QINT16:\n\u001B[0;32m    527\u001B[0m         _np_qint16,\n\u001B[0;32m    528\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_QUINT16:\n\u001B[0;32m    529\u001B[0m         _np_quint16,\n\u001B[0;32m    530\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_QINT32:\n\u001B[0;32m    531\u001B[0m         _np_qint32,\n\u001B[0;32m    532\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_BFLOAT16:\n\u001B[0;32m    533\u001B[0m         _np_bfloat16,\n\u001B[0;32m    534\u001B[0m \n\u001B[0;32m    535\u001B[0m     \u001B[38;5;66;03m# Ref types\u001B[39;00m\n\u001B[0;32m    536\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_HALF_REF:\n\u001B[0;32m    537\u001B[0m         np\u001B[38;5;241m.\u001B[39mfloat16,\n\u001B[0;32m    538\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_FLOAT_REF:\n\u001B[0;32m    539\u001B[0m         np\u001B[38;5;241m.\u001B[39mfloat32,\n\u001B[0;32m    540\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_DOUBLE_REF:\n\u001B[0;32m    541\u001B[0m         np\u001B[38;5;241m.\u001B[39mfloat64,\n\u001B[0;32m    542\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_INT32_REF:\n\u001B[0;32m    543\u001B[0m         np\u001B[38;5;241m.\u001B[39mint32,\n\u001B[0;32m    544\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_UINT32_REF:\n\u001B[0;32m    545\u001B[0m         np\u001B[38;5;241m.\u001B[39muint32,\n\u001B[0;32m    546\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_UINT8_REF:\n\u001B[0;32m    547\u001B[0m         np\u001B[38;5;241m.\u001B[39muint8,\n\u001B[0;32m    548\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_UINT16_REF:\n\u001B[0;32m    549\u001B[0m         np\u001B[38;5;241m.\u001B[39muint16,\n\u001B[0;32m    550\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_INT16_REF:\n\u001B[0;32m    551\u001B[0m         np\u001B[38;5;241m.\u001B[39mint16,\n\u001B[0;32m    552\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_INT8_REF:\n\u001B[0;32m    553\u001B[0m         np\u001B[38;5;241m.\u001B[39mint8,\n\u001B[0;32m    554\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_STRING_REF:\n\u001B[0;32m    555\u001B[0m         np\u001B[38;5;241m.\u001B[39mobject,\n\u001B[0;32m    556\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_COMPLEX64_REF:\n\u001B[0;32m    557\u001B[0m         np\u001B[38;5;241m.\u001B[39mcomplex64,\n\u001B[0;32m    558\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_COMPLEX128_REF:\n\u001B[0;32m    559\u001B[0m         np\u001B[38;5;241m.\u001B[39mcomplex128,\n\u001B[0;32m    560\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_INT64_REF:\n\u001B[0;32m    561\u001B[0m         np\u001B[38;5;241m.\u001B[39mint64,\n\u001B[0;32m    562\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_UINT64_REF:\n\u001B[0;32m    563\u001B[0m         np\u001B[38;5;241m.\u001B[39muint64,\n\u001B[0;32m    564\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_BOOL_REF:\n\u001B[0;32m    565\u001B[0m         np\u001B[38;5;241m.\u001B[39mbool,\n\u001B[0;32m    566\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_QINT8_REF:\n\u001B[0;32m    567\u001B[0m         _np_qint8,\n\u001B[0;32m    568\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_QUINT8_REF:\n\u001B[0;32m    569\u001B[0m         _np_quint8,\n\u001B[0;32m    570\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_QINT16_REF:\n\u001B[0;32m    571\u001B[0m         _np_qint16,\n\u001B[0;32m    572\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_QUINT16_REF:\n\u001B[0;32m    573\u001B[0m         _np_quint16,\n\u001B[0;32m    574\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_QINT32_REF:\n\u001B[0;32m    575\u001B[0m         _np_qint32,\n\u001B[0;32m    576\u001B[0m     types_pb2\u001B[38;5;241m.\u001B[39mDT_BFLOAT16_REF:\n\u001B[0;32m    577\u001B[0m         _np_bfloat16,\n\u001B[0;32m    578\u001B[0m }\n\u001B[0;32m    580\u001B[0m _QUANTIZED_DTYPES_NO_REF \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mfrozenset\u001B[39m([qint8, quint8, qint16, quint16, qint32])\n\u001B[0;32m    581\u001B[0m _QUANTIZED_DTYPES_REF \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mfrozenset\u001B[39m(\n\u001B[0;32m    582\u001B[0m     [qint8_ref, quint8_ref, qint16_ref, quint16_ref, qint32_ref])\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Thesis_Work\\lib\\site-packages\\numpy\\__init__.py:305\u001B[0m, in \u001B[0;36m__getattr__\u001B[1;34m(attr)\u001B[0m\n\u001B[0;32m    300\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    301\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIn the future `np.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mattr\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m` will be defined as the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    302\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcorresponding NumPy scalar.\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;167;01mFutureWarning\u001B[39;00m, stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m    304\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m attr \u001B[38;5;129;01min\u001B[39;00m __former_attrs__:\n\u001B[1;32m--> 305\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(__former_attrs__[attr])\n\u001B[0;32m    307\u001B[0m \u001B[38;5;66;03m# Importing Tester requires importing all of UnitTest which is not a\u001B[39;00m\n\u001B[0;32m    308\u001B[0m \u001B[38;5;66;03m# cheap import Since it is mainly used in test suits, we lazy import it\u001B[39;00m\n\u001B[0;32m    309\u001B[0m \u001B[38;5;66;03m# here to save on the order of 10 ms of import time for most users\u001B[39;00m\n\u001B[0;32m    310\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m    311\u001B[0m \u001B[38;5;66;03m# The previous way Tester was imported also had a side effect of adding\u001B[39;00m\n\u001B[0;32m    312\u001B[0m \u001B[38;5;66;03m# the full `numpy.testing` namespace\u001B[39;00m\n\u001B[0;32m    313\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m attr \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtesting\u001B[39m\u001B[38;5;124m'\u001B[39m:\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'numpy' has no attribute 'object'.\n`np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. \nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Reshape features into a 2D array suitable for CNN\n",
    "features_2d = features.reshape(features.shape[0], features.shape[1], 1)\n",
    "\n",
    "# Convert labels to categorical\n",
    "labels_categorical = to_categorical(labels)\n",
    "\n",
    "# Define the CNN model\n",
    "def create_cnn_model(filters=32, kernel_size=3, activation='relu', dropout_rate=0.5):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation=activation, input_shape=(features_2d.shape[1], 1)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(labels_categorical.shape[1], activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Wrap the model in KerasClassifier for GridSearchCV compatibility\n",
    "model = KerasClassifier(build_fn=create_cnn_model)"
   ],
   "id": "97d87f7e50929bce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define the parameter grid for tuning\n",
    "param_grid = {\n",
    "    'filters': [16, 32, 64],\n",
    "    'kernel_size': [3, 5],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'dropout_rate': [0.3, 0.5],\n",
    "    'epochs': [50, 100],\n",
    "    'batch_size': [32, 64]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='accuracy')\n",
    "grid_search.fit(features_2d, labels_categorical)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best parameters: \", best_params)\n",
    "print(\"Best score: \", best_score)"
   ],
   "id": "fb6d90b64022c192"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fc768fe74e0dde3f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b6b90fd87cef099f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
